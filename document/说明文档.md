

##引言
###编写目的
目前开源的语音识别算法都存在识别准确率不够高的问题，所以我们的目标是在已有的一些成果的基础上，站在巨人的肩膀上，开发出准确率更高的语音识别系统，实现从语音到拼音到汉字的识别转换，包括对阿拉伯数字，不包括英文识别。通过此文档，用户可以大致了解我们的项目以及软件的使用方法。
###背景
我们的项目名称是语音识别系统。进入21世纪，因特网得到了普及，每台电脑都可以连入万维网，同时，移动互联网技术也得到了快速发展，便携计算机设备从以往的笨重的PDA设备，变为当前的智能手机系统，一台智能手机的计算能力已经远远高于90年代的一台个人电脑。同时随着移动互联网技术的发展，手机上网速度越来越快，这给语音识别技术的发展和应用带来了新的平台。随着硬件设备越来越廉价以及云计算技术的出现，也大大的推动了语音识别的研究和应用。在技术应用方面，语音识别的应用已经不再像原有的“单机模式”，即一台设备一套识别系统，转而采用“云模式”，设备上仅仅保留识别的前端，真正的识别解码放置到云端。这样做的好处是，服务提供商可以随时更新语言及声学模型，同时用户无需保留非常大的各种模型，也获得了实惠和方便。随着移动设备的不断普及，当前，移动设备的在个人用户中已经逐步取代了个人电脑的地位，因此，移动应用方兴未艾，一系列语音应用如雨后春笋般冒出，其中最出名的莫过于苹果iPhone手机的Siri语音助手和Google的语音搜索系统。在识别技术的理论研究方面，首先是解码网络构建上得到了发展，得益于计算机硬件的发展，让基于加权有限状态转换机(WeightedFinite-State Transducer：WFST)的语音识别解码器从理论上得到了完善，从实践上也得到了更加广泛的应用。另外，声学模型的建模技术也获得不断提高，异方差线性区分分析技术、说话人自适应训练技术、说话人高斯化技术以及鉴别性声学模型训练包括最小分类错误准则，最小音素错误准则等。另一方面，近几年，基于上下文相关的深度置信神经网络（Deep Belief Nets：DBN）声学模型训练也取得了巨大的成功。LVCSR的架构有从原来的GMM-HMM逐渐转变为了DNN—HMM的趋势。

语音识别技术历经半个多世纪的发展慢慢趋于成熟，正逐步从实验室理论研究走向应用市场，与其相关的应用和任务也逐渐进入到人们的日常生活中。当前科技进步的速度可以突飞猛进来形容，可以预见在未来，语音识别技术会在全世界各项全面进步和语音研究人员的共同努力下越来越实用，从而让高可靠性的便捷人机交互能直接服务人们的工作和生活。
###参考资料
github项目：

+ 中华新华字典数据库：https://github.com/pwxcoo/chinese-xinhua

+ 汉字拼音数据：https://github.com/mozillazg/pinyin-data

+ 词语拼音数据：https://github.com/mozillazg/phrase-pinyin-data

+ 自然语言处理语料库：https://github.com/SophonPlus/ChineseNlpCorpus

+ 中文自然语言处理相关资料：https://github.com/crownpku/Awesome-Chinese-NLP

+ 中文句子纠错：https://github.com/shibing624/pycorrector

+ pyime的输入法：https://github.com/fxsjy/pyime

+ 搜喵输入法：https://github.com/crownpku/Somiao-Pinyin

+ 语音识别项目：https://github.com/libai3/masr

+ 语音识别项目：https://github.com/xxbb1234021/speech_recognition

+ 语音识别项目：https://github.com/nl8590687/ASRT_SpeechRecognition

+ 拼音注音：https://github.com/mozillazg/python-pinyin



论文：

+ 《Language Modeling with Gated Convolutional Networks》：https://arxiv.org/abs/1612.08083

+ 《Attention Is All You Need》：https://arxiv.org/abs/1706.03762

+ 《Highway Networks》：https://arxiv.org/abs/1505.00387

+ 《Fast and Accurate Entity Recognition with Iterated Dilated Convolutions》：https://arxiv.org/abs/1702.02098

##使用过程


###开发环境

编程语言：python 

用到的Python IDE：Pycharm、IDLE、sublime、VScode

调用的库：numpy、tensorflow、keras、librosa、cn2an

###输入
点击开始录音后，对着麦克风读想要识别的句子，即时录音得到声音文件。

或者可以选择电脑本地的音频文件，目前支持的音频格式有.wav和.mp3两种。


###输出
对于输入的音频文件进行识别后，会输出两行内容。

一行是拼音，每个字之间有间隔，每个字的拼音后面用1234表示四个声调，5表示轻声，如读入“声音”，输出的拼音为“sheng1 yin1”

一行是文字，即对拼音通过语言模型识别成汉字。如果程序对识别的汉字有较大的不确定，他会自动标红，用户认为错误即可鼠标选中后进行重读校正，对新识别的文字如果正确即可点击替换键实现替换掉错误的汉字，如果仍然不正确即可不断重录直到正确为止。

###界面展示

![0ERJ{$94D4F7[N4}JY(2LA5.png](https://i.loli.net/2019/07/10/5d254e946dcd260600.png)](https://i.loli.net/2019/07/10/5d254e946dcd260600.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190710104127370.png)：开始录音

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190710104245869.png)：录音结束

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190710104250616.png)：选择本地的音频文件（.wav/.mp3）

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190710104255757.png) ：音频录制或选择完成，开始语音识别

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190710104302157.png)：对需要替换的内容重新读并生成新的识别出来的文字

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190710104306854.png)：识别正确后确定替换

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190710104312599.png)：全部替换完成后，点击按键文字会变成全黑，即整个识别过程完成


![在这里插入图片描述](https://img-blog.csdnimg.cn/20190710104318868.png)：清空该次识别，可以开始新一轮语音识别

##整体框架
###选择的模型
声学模型选用的是DCBNN1D，参考了ASRT_SpeechRecognition，编写了用于处理音频的模型

语言模型隐马尔科夫模型（HMM)

###数据集
**声学部分**使用了5个数据集，分别是：

+ THCHS30：万余条语音文件，大约40小时。内容以文章诗句为主，全部为女声。（清华大学语音与语言技术中心（CSLT）出版）
+ ST-CMDS：10万余条语音文件，大约100余小时。内容以平时的网上语音聊天和智能语音控制语句为主，855个不同说话者，同时有男声和女声，适合多种场景下使用。
+ AISHELL开源版：包含178小时的开源版数据。包含400个来自中国不同地区、具有不同的口音的人的声音。录音质量高，通过专业的语音注释和严格的质量检查，手动转录准确率达到95％以上。
+ Primewords Chinese Corpus Set 1：包含了大约100小时的中文语音数据。语料库由296名母语为英语的智能手机录制。转录准确度大于98％，置信水平为95％。抄本和话语之间的映射以JSON格式给出。
+ Aidatatang_200zh：200小时(当前时长最长的中文开源语音数据集)，由Android系统手机（16kHz，16位）和iOS系统手机（16kHz，16位）记录。录音环境安静，录音者性别、年龄均匀分布。每个句子的手动转录准确率大于98％。

**语言模型**部分使用了以下项目提供的数据集：

https://github.com/brightmart/nlp_chinese_corpus：wiki

维基百科json版,104万个词条(1,043,224条; 原始文件大小1.6G，压缩文件519M)

**结构：**{"id":<id>,"url":<url>,"title":<title>,"text":<text>} 其中，title是词条的标题，text是正文；通过"\n\n"换行。

**示例：**{"id": "53", "url": "https://zh.wikipedia.org/wiki?curid=53", "title": "经济学", "text": "经济学

经济学是一门对产品和服务的生产、分配以及消费进行研究的社会科学。西方语言中的“经济学”一词源于古希腊的。

经济学注重的是研究经济行为者在一个经济体系下的行为，以及他们彼此之间的互动。在现代，经济学的教材通常将这门领域的研究分为总体经济学和个体经济学。微观经济学检视一个社会里基本层次的行为，包括个体的行为者（例如个人、公司、买家或卖家）以及与市场的互动。而宏观经济学则分析整个经济体和其议题，包括失业、通货膨胀、经济成长、财政和货币政策等。..."}

[![wiki_zh.jpg](https://i.loli.net/2019/07/10/5d258f04ca5bd62777.jpg)](https://i.loli.net/2019/07/10/5d258f04ca5bd62777.jpg)

###UI框架

UI部分因为不需要做成web或者app所以只需要一个简单的界面，供用户进行交互即可。每一层相应位置设置按钮并实现一个功能。声学模型和语言模型相当于是一个黑箱供UI调用，UI通过录音或者读取文件向声学模型提供音频，并接收声学模型和语言模型识别出来的结果。

![0ERJ{$94D4F7[N4}JY(2LA5.png](https://i.loli.net/2019/07/10/5d254e946dcd260600.png)](https://i.loli.net/2019/07/10/5d254e946dcd260600.png)

[![第一层.png](https://i.loli.net/2019/07/10/5d259afa8b2ae16041.png)](https://i.loli.net/2019/07/10/5d259afa8b2ae16041.png)  第一层是用户交互的按键

[![第二层.png](https://i.loli.net/2019/07/10/5d259be77be5b58854.png)](https://i.loli.net/2019/07/10/5d259be77be5b58854.png)   第二层选择声学模型和语言模型，但是目前用的声学模型和语言模型都只有一个，所以该层的功能还没有用到

[![第三层.png](https://i.loli.net/2019/07/10/5d259ccf2b2d264644.png)](https://i.loli.net/2019/07/10/5d259ccf2b2d264644.png)   第三层显示由识别的拼音得到的汉字

[![第四层.png](https://i.loli.net/2019/07/10/5d259d06264e486035.png)](https://i.loli.net/2019/07/10/5d259d06264e486035.png)   第四层显示声学模型得到的拼音

## 体系架构
acoustic下是声学模型

- Reader是读取各种数据集，和数据生成器的类
- 其他py文件是各自的模型，调用通用的接口，compile、save、load、fit

core下是各种模型用到的层

examples下是训练各种模型的方法
feature下是特征提取方法，需要实现基于batch的提取

language下是语言模型实现

- TODO 需要实现Reader

util下是各种工具，包括拼音处理的，用于损失函数绘制的...等

visualization下是可视化工具，用来提供一个UI工具

jointly 下是联合训练模型，从语音->汉字的端到端模型


##结构图

[![UML.png](https://i.loli.net/2019/07/10/5d2598a51c9cf23778.png)](https://i.loli.net/2019/07/10/5d2598a51c9cf23778.png)

##评价指标
+ **WER 字错误率 Word Error Rate**

为了使识别出来的词序列和标准的词序列之间保持一致，需要进行替换、删除或者插入某些词，这些插入、替换或删除的词的总个数，除以标准的词序列中词的总个数的百分比，即为WER。

公式为： [![WER.jpg](https://i.loli.net/2019/07/10/5d259effcf0c234517.jpg)](https://i.loli.net/2019/07/10/5d259effcf0c234517.jpg)


Substitution——替换

Deletion——删除

Insertion——插入

N——单词数目

+ **SER句错误率，Sentence Error Rate**

SER表述为句子中如果有一个词识别错误，那么这个句子被认为识别错误，句子识别错误的的个数，除以总的句子个数即为SER

其计算公式如下所示： [![SER.png](https://i.loli.net/2019/07/10/5d259f5f1514a90391.png)](https://i.loli.net/2019/07/10/5d259f5f1514a90391.png)

+ 注意事项

WER可以分男女、快慢、口音、数字/英文/中文等情况，分别来看。

因为有插入词，所以理论上WER有可能大于100%，但实际中、特别是大样本量的时候，是不可能的，否则就太差了，不可能被商用。

站在纯产品体验角度，很多人会以为识别率应该等于“句子识别正确的个数/总的句子个数”，即“识别（正确）率等于96%”这种，实际工作中，这个应该指向“SER（句错误率，Sentence Error Rate）”，即“句子识别错误的个数/总的句子个数”。不过据说在实际工作中，一般句错误率是字错误率的2~3倍，所以可能就不怎么看了。




## 本项目的优点
- 数据接口易于使用，常用的几个数据集已经实现了接口，只需要下载，解压，在配置文件中更改路径后，即可运行清洗方法，并自动获取所有音频和标注
- 模型类已经写好，只需要关注模型结构，并保证输入输出格式，之后只需不到10行代码即可完成自动保存、训练
- 集成了目前的几个开源项目中的模型，并训练了相应的模型文件
- 较为详细的注释和清晰的代码，易于学习和修改

